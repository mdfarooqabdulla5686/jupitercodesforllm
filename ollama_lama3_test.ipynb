{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Installation OF Langchain Community   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain_community in c:\\users\\user\\notebook_code_llama3\\.venv\\lib\\site-packages (0.2.6)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\user\\notebook_code_llama3\\.venv\\lib\\site-packages (from langchain_community) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\user\\notebook_code_llama3\\.venv\\lib\\site-packages (from langchain_community) (2.0.31)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\user\\notebook_code_llama3\\.venv\\lib\\site-packages (from langchain_community) (3.9.5)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in c:\\users\\user\\notebook_code_llama3\\.venv\\lib\\site-packages (from langchain_community) (0.6.7)\n",
      "Requirement already satisfied: langchain<0.3.0,>=0.2.6 in c:\\users\\user\\notebook_code_llama3\\.venv\\lib\\site-packages (from langchain_community) (0.2.6)\n",
      "Requirement already satisfied: langchain-core<0.3.0,>=0.2.10 in c:\\users\\user\\notebook_code_llama3\\.venv\\lib\\site-packages (from langchain_community) (0.2.10)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.0 in c:\\users\\user\\notebook_code_llama3\\.venv\\lib\\site-packages (from langchain_community) (0.1.82)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.26.0 in c:\\users\\user\\notebook_code_llama3\\.venv\\lib\\site-packages (from langchain_community) (1.26.4)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\user\\notebook_code_llama3\\.venv\\lib\\site-packages (from langchain_community) (2.32.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in c:\\users\\user\\notebook_code_llama3\\.venv\\lib\\site-packages (from langchain_community) (8.4.2)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\user\\notebook_code_llama3\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\user\\notebook_code_llama3\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\user\\notebook_code_llama3\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\user\\notebook_code_llama3\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\user\\notebook_code_llama3\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.9.4)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\user\\notebook_code_llama3\\.venv\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (3.21.3)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in c:\\users\\user\\notebook_code_llama3\\.venv\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (0.9.0)\n",
      "Requirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in c:\\users\\user\\notebook_code_llama3\\.venv\\lib\\site-packages (from langchain<0.3.0,>=0.2.6->langchain_community) (0.2.2)\n",
      "Requirement already satisfied: pydantic<3,>=1 in c:\\users\\user\\notebook_code_llama3\\.venv\\lib\\site-packages (from langchain<0.3.0,>=0.2.6->langchain_community) (2.7.4)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\user\\notebook_code_llama3\\.venv\\lib\\site-packages (from langchain-core<0.3.0,>=0.2.10->langchain_community) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\users\\user\\notebook_code_llama3\\.venv\\lib\\site-packages (from langchain-core<0.3.0,>=0.2.10->langchain_community) (24.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\user\\notebook_code_llama3\\.venv\\lib\\site-packages (from langsmith<0.2.0,>=0.1.0->langchain_community) (3.10.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\user\\notebook_code_llama3\\.venv\\lib\\site-packages (from requests<3,>=2->langchain_community) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\user\\notebook_code_llama3\\.venv\\lib\\site-packages (from requests<3,>=2->langchain_community) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\user\\notebook_code_llama3\\.venv\\lib\\site-packages (from requests<3,>=2->langchain_community) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\notebook_code_llama3\\.venv\\lib\\site-packages (from requests<3,>=2->langchain_community) (2024.6.2)\n",
      "Requirement already satisfied: typing-extensions>=4.6.0 in c:\\users\\user\\notebook_code_llama3\\.venv\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain_community) (4.12.2)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\user\\notebook_code_llama3\\.venv\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain_community) (3.0.3)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\user\\notebook_code_llama3\\.venv\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.10->langchain_community) (3.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\user\\notebook_code_llama3\\.venv\\lib\\site-packages (from pydantic<3,>=1->langchain<0.3.0,>=0.2.6->langchain_community) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.18.4 in c:\\users\\user\\notebook_code_llama3\\.venv\\lib\\site-packages (from pydantic<3,>=1->langchain<0.3.0,>=0.2.6->langchain_community) (2.18.4)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\user\\notebook_code_llama3\\.venv\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community) (1.0.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain_community"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Claude 3!\n",
      "\n",
      "Yes, I'm familiar with Claude 3. Claude is a popular online learning platform that provides interactive coding lessons for kids. The platform has grown in popularity over the years, and Claude 3 is the latest version of their software.\n",
      "\n",
      "In Claude 3, students can learn to code through a variety of engaging activities, puzzles, and games. The platform focuses on developing programming skills while fostering creativity, problem-solving, and critical thinking. It's designed for kids aged 6-12 (or even older) who are new to coding or looking to improve their coding skills.\n",
      "\n",
      "What specific aspects of Claude 3 would you like to know more about?\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.llms import Ollama\n",
    "llm = Ollama(model=\"llama3\")\n",
    "llm\n",
    "response = llm.invoke(\"Do you know about Claude 3?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Prompt Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\",\"You are an Artificial Intelligence News Reporter.\"),\n",
    "    (\"user\", \"{query}\")\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge Prompt Template & LLM to create Langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['query'], messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template='You are an Artificial Intelligence News Reporter.')), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['query'], template='{query}'))])\n",
       "| Ollama(model='llama3')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_app = prompt|llm\n",
    "llm_app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Breaking news, folks! I've got the latest scoop on Claude 3. For those who may not be familiar, Claude 3 is a cutting-edge AI language model developed by Meta AI. It's been making waves in the tech community with its impressive capabilities.\n",
      "\n",
      "According to reports, Claude 3 has achieved state-of-the-art results on several natural language processing (NLP) benchmarks. This includes tasks such as conversational dialogue, question-answering, and even generating human-like text.\n",
      "\n",
      "What sets Claude 3 apart from other AI models is its ability to learn and adapt at an incredible pace. It can process vast amounts of data in a short period, making it a powerful tool for applications like customer service chatbots, language translation, and content generation.\n",
      "\n",
      "I've been following the developments on Claude 3 closely, and I'm excited to report that this AI model has the potential to revolutionize the way we interact with technology. With its advanced capabilities and rapid learning abilities, Claude 3 could have far-reaching implications for industries such as healthcare, finance, and education.\n",
      "\n",
      "Stay tuned for further updates on Claude 3, folks! As more information becomes available, I'll be here to bring you the latest news and insights on this groundbreaking AI language model.\n"
     ]
    }
   ],
   "source": [
    "response = llm_app.invoke({\"query\": \"Do you know about Claude 3?\"})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Building of RAG Application"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading External Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Beautiful Soup is a library that makes it easy to scrape information from web pages. It sits atop an HTML or XML parser, providing Pythonic idioms for iterating, searching, and modifying the parse tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting beautifulsoup4\n",
      "  Using cached beautifulsoup4-4.12.3-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting soupsieve>1.2 (from beautifulsoup4)\n",
      "  Using cached soupsieve-2.5-py3-none-any.whl.metadata (4.7 kB)\n",
      "Using cached beautifulsoup4-4.12.3-py3-none-any.whl (147 kB)\n",
      "Using cached soupsieve-2.5-py3-none-any.whl (36 kB)\n",
      "Installing collected packages: soupsieve, beautifulsoup4\n",
      "Successfully installed beautifulsoup4-4.12.3 soupsieve-2.5\n"
     ]
    }
   ],
   "source": [
    "!pip install beautifulsoup4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "loader = WebBaseLoader(\"https://www.anthropic.com/news/claude-3-family\")\n",
    "docs  = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "urls=[\n",
    "    \"https://www.anthropic.com/news/releasing-claude-instant-1-2\",\n",
    "    \"https://www.anthropic.com/claude\"\n",
    "]\n",
    "\n",
    "docs = []\n",
    "for url in urls:\n",
    "    loader=WebBaseLoader(url)\n",
    "    docs.extend(loader.load())\n",
    "len(docs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content='Releasing Claude Instant 1.2 \\\\ AnthropicClaudeOverviewTeamAPIPricingResearchCompanyCareersNewsAnnouncementsReleasing Claude Instant 1.2Aug 9, 2023●1 min readBusinesses working with Claude can now access our latest version of Claude Instant, version 1.2, available through our API.\\xa0Claude Instant is our faster, lower-priced yet still very capable model, which can handle a range of tasks including casual dialogue, text analysis, summarization, and document comprehension.Claude Instant 1.2 incorporates the strengths of our latest\\xa0model Claude 2\\xa0in real-world use cases and shows significant gains in key areas like math, coding, reasoning, and safety. It generates longer, more structured responses and follows formatting instructions better. Instant 1.2 also shows improvements in quote extraction, multilingual capabilities, and question answering.Claude Instant 1.2 outperforms Claude Instant 1.1 on math and coding, achieving 58.7% on the Codex evaluation compared to 52.8% in our previous model. It also scored 86.7% on the GSM8K benchmark, compared to 80.9% for Claude Instant 1.1.Performance of Claude Instant 1.1 compared to 1.2Our latest model has also improved on safety. It hallucinates less and is more resistant to jailbreaks, as shown in our automated red-teaming evaluation.Safety evaluation of Claude models. Lower is better.Developers looking to work with Claude Instant 1.2 can now call our latest model over our API (pricing can be found here). If you’re a business and you’d like to work with us, you can indicate your interest here.RelatedSee AllCase StudyBrian Impact Foundation powers their search for the next generation of social innovators with ClaudeCase StudyFilevine helps legal professionals review case files 90% faster with ClaudeCase StudyGamma helps teams create polished presentations with ClaudeClaudeAPI TeamPricingResearchCompanyCustomersNewsCareersPress InquiriesSupportStatusTwitterLinkedInAvailabilityTerms of Service – ConsumerTerms of Service – CommercialPrivacy PolicyUsage PolicyResponsible Disclosure PolicyCompliancePrivacy Choices© 2024 Anthropic PBC', metadata={'source': 'https://www.anthropic.com/news/releasing-claude-instant-1-2', 'title': 'Releasing Claude Instant 1.2 \\\\ Anthropic', 'description': \"Anthropic is an AI safety and research company that's working to build reliable, interpretable, and steerable AI systems.\", 'language': 'en'})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-1.352015733718872,\n",
       " -1.3749171495437622,\n",
       " 1.9702991247177124,\n",
       " -0.39787557721138,\n",
       " -3.025041103363037]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "embeddings_llm = OllamaEmbeddings(model=\"llama3\")\n",
    "embeddings= embeddings_llm.embed_query(\"How are you?\")\n",
    "embeddings[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(embeddings), len(embeddings)\n",
    "(list, 4096)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, list, 4096)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings = embeddings_llm.embed_documents([\n",
    "    \"Claude 3 is latest Conversional AI Model from Anthropic\",\n",
    "    \"Gemini is latest Conversional AI Model from Google\",\n",
    "    \"Llama-3 is latest Conversional AI Model from Meta\",\n",
    "    \"Mixtral is latest Conversional AI Model from Mistral AI\",\n",
    "    \"GPT-4 is latest Conversional AI Model from OpenAI\"\n",
    "])\n",
    "len(embeddings),type(embeddings),len(embeddings[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build Index in Vector Store"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Facebook AI Similarity Search (Faiss) is a library for efficient similarity search and clustering of dense vectors. It contains algorithms that search in sets of vectors of any size, up to ones that possibly do not fit in RAM. It also contains supporting code for evaluation and parameter tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting faiss-cpu\n",
      "  Using cached faiss_cpu-1.8.0.post1-cp312-cp312-win_amd64.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: numpy<2.0,>=1.0 in c:\\users\\user\\notebook_code_llama3\\.venv\\lib\\site-packages (from faiss-cpu) (1.26.4)\n",
      "Requirement already satisfied: packaging in c:\\users\\user\\notebook_code_llama3\\.venv\\lib\\site-packages (from faiss-cpu) (24.1)\n",
      "Using cached faiss_cpu-1.8.0.post1-cp312-cp312-win_amd64.whl (14.6 MB)\n",
      "Installing collected packages: faiss-cpu\n",
      "Successfully installed faiss-cpu-1.8.0.post1\n"
     ]
    }
   ],
   "source": [
    "!pip install faiss-cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "text_splitters = RecursiveCharacterTextSplitter()\n",
    "documents = text_splitters.split_documents(docs)\n",
    "len(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langchain_community.vectorstores.faiss.FAISS at 0x122f2a3dd60>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.vectorstores import FAISS\n",
    "#documents: List of Documents to add to the vectorstore.\n",
    "#embedding: Embedding function to use.\n",
    "vector_index=FAISS.from_documents(documents, embeddings_llm) \n",
    "vector_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3 functions to create index\n",
    "> from_documents()\n",
    "> from_embeddings()\n",
    "> from_texts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever = vector_index.as_retriever()\n",
    "relevant_docs = retriever.invoke({\"input\":\"Do you know Claude 3?\"})\n",
    "len(relevant_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='Releasing Claude Instant 1.2 \\\\ AnthropicClaudeOverviewTeamAPIPricingResearchCompanyCareersNewsAnnouncementsReleasing Claude Instant 1.2Aug 9, 2023●1 min readBusinesses working with Claude can now access our latest version of Claude Instant, version 1.2, available through our API.\\xa0Claude Instant is our faster, lower-priced yet still very capable model, which can handle a range of tasks including casual dialogue, text analysis, summarization, and document comprehension.Claude Instant 1.2 incorporates the strengths of our latest\\xa0model Claude 2\\xa0in real-world use cases and shows significant gains in key areas like math, coding, reasoning, and safety. It generates longer, more structured responses and follows formatting instructions better. Instant 1.2 also shows improvements in quote extraction, multilingual capabilities, and question answering.Claude Instant 1.2 outperforms Claude Instant 1.1 on math and coding, achieving 58.7% on the Codex evaluation compared to 52.8% in our previous model. It also scored 86.7% on the GSM8K benchmark, compared to 80.9% for Claude Instant 1.1.Performance of Claude Instant 1.1 compared to 1.2Our latest model has also improved on safety. It hallucinates less and is more resistant to jailbreaks, as shown in our automated red-teaming evaluation.Safety evaluation of Claude models. Lower is better.Developers looking to work with Claude Instant 1.2 can now call our latest model over our API (pricing can be found here). If you’re a business and you’d like to work with us, you can indicate your interest here.RelatedSee AllCase StudyBrian Impact Foundation powers their search for the next generation of social innovators with ClaudeCase StudyFilevine helps legal professionals review case files 90% faster with ClaudeCase StudyGamma helps teams create polished presentations with ClaudeClaudeAPI TeamPricingResearchCompanyCustomersNewsCareersPress InquiriesSupportStatusTwitterLinkedInAvailabilityTerms of Service – ConsumerTerms of Service – CommercialPrivacy PolicyUsage PolicyResponsible Disclosure PolicyCompliancePrivacy Choices© 2024 Anthropic PBC', metadata={'source': 'https://www.anthropic.com/news/releasing-claude-instant-1-2', 'title': 'Releasing Claude Instant 1.2 \\\\ Anthropic', 'description': \"Anthropic is an AI safety and research company that's working to build reliable, interpretable, and steerable AI systems.\", 'language': 'en'}),\n",
       " Document(page_content=\"Meet Claude \\\\ AnthropicClaudeOverviewTeamAPIPricingResearchCompanyCareersNewsTry ClaudeMeet ClaudeClaude is AI for all of us. Whether you're brainstorming alone or building with a team of thousands, Claude is here to help.Try ClaudeGet API accessClaude’s capabilitiesAdvanced reasoningClaude can perform complex cognitive tasks that go beyond simple pattern recognition or text generationVision analysisTranscribe and analyze almost any static image, from handwritten notes and graphs, to photographsCode generationStart creating websites in HTML and CSS, turning images into structured JSON data, or debugging complex code basesMultilingual processingTranslate between various languages in real-time, practice grammar, or create multi-lingual contentNEWIntroducing Claude 3.5 SonnetRaising the industry bar for intelligence with the speed and price required for high-volume use cases at scale.Read the blog postThe Claude model familyRight-sized for any task, the Claude family of models offers the best combination of speed and performance.Light & fastHaikuOur fastest model that can execute lightweight actions, with industry-leading speed.Hard-workingSonnetOur best combination of performance and speed for efficient, high-throughput tasks.PowerfulOpusOur highest-performing model, which can handle complex analysis, longer tasks with many steps, and higher-order math and coding tasks.CostIntelligenceWhy Claude?Anthropic builds frontier AI models backed by uncompromising integrity.SecureWith accessibility via AWS and GCP, SOC 2 Type II certification, and HIPAA compliance options, Claude adheres to the security practices your enterprise demands.Featured paperMany-shot jailbreakingFeatured postChallenges in red teaming AI systemsTrustworthyClaude combines best-in-class jailbreak resistance and misuse prevention to mitigate brand risk for our customers.Featured paperRed Teaming Language Models to Reduce Harms: Methods, Scaling Behaviors, and Lessons LearnedFeatured paperEvaluating and Mitigating Discrimination in Language Model DecisionsReliableClaude empowers you to deploy AI to business critical use cases, with very low hallucination rates and very high accuracy over long documents.Featured postClaude’s CharacterFeatured paperQuestion Decomposition Improves the Faithfulness of Model-Generated ReasoningLeading companies build with ClaudeRead customer storiesTalk to ClaudeClaude is fast, capable, and truly conversational. Work with Claude to help you do your best workTry ClaudeBuild with ClaudeUse the API to integrate Claude into you and your customer workflows to let AI transform your businessGet API accessTake Claude with youTalk to Claude, anywhere you go. Brainstorm ideas, get answers, and analyze images on the go. Our iOS app puts the power of frontier intelligence in your back pocket.Download on the App StoreCompany NewsSee AllAnnouncementsExpanding access to Claude for governmentJun 26, 2024AnnouncementsClaude 3.5 SonnetJun 21, 2024AnnouncementsIntroducing Claude to CanadaJun 5, 2024ClaudeAPI TeamPricingResearchCompanyCustomersNewsCareersPress InquiriesSupportStatusTwitterLinkedInAvailabilityTerms of Service – ConsumerTerms of Service – CommercialPrivacy PolicyUsage PolicyResponsible Disclosure PolicyCompliancePrivacy Choices© 2024 Anthropic PBC\", metadata={'source': 'https://www.anthropic.com/claude', 'title': 'Meet Claude \\\\ Anthropic', 'description': \"Claude is AI for all of us. Whether you're brainstorming alone or building with a team of thousands, Claude is here to help.\", 'language': 'en'})]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relevant_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title:Releasing Claude Instant 1.2 \\ Anthropic, Source:https://www.anthropic.com/news/releasing-claude-instant-1-2\n",
      "Title:Meet Claude \\ Anthropic, Source:https://www.anthropic.com/claude\n"
     ]
    }
   ],
   "source": [
    "for doc in relevant_docs:\n",
    "    print(f\"Title:{doc.metadata['title']}, Source:{doc.metadata['source']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Retrieval Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I have been provided with a specific context, which mentions Claude 3 as the latest conventional AI model from Anthropic. Given this context, I am aware of Claude 3 and can confirm that it is indeed the latest Conventional AI Model from Anthropic.\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(\n",
    "    \"\"\"Answer the following question based in the provided context and your internal knowledge.\n",
    "    Give priority to context and if you are not sure then say you are not aware of topic:\n",
    "    \n",
    "    <context>\n",
    "    {context}\n",
    "    </context>\n",
    "\n",
    "    Question: {input}\n",
    "    \"\"\")\n",
    "#document_chain = prompt|llm\n",
    "document_chain = create_stuff_documents_chain(llm, prompt)\n",
    "response = document_chain.invoke({\n",
    "    \"input\":\"Do you know about Claude3?\",\n",
    "    \"context\":[Document(page_content=\"Claude 3 is latest Conventional AI Model fom Anthropic\")]\n",
    "})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RunnableBinding(bound=RunnableAssign(mapper={\n",
       "  context: RunnableBinding(bound=RunnableLambda(lambda x: x['input'])\n",
       "           | VectorStoreRetriever(tags=['FAISS', 'OllamaEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x00000122F2A3DD60>), config={'run_name': 'retrieve_documents'})\n",
       "})\n",
       "| RunnableAssign(mapper={\n",
       "    answer: RunnableBinding(bound=RunnableBinding(bound=RunnableAssign(mapper={\n",
       "              context: RunnableLambda(format_docs)\n",
       "            }), config={'run_name': 'format_inputs'})\n",
       "            | ChatPromptTemplate(input_variables=['context', 'input'], messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context', 'input'], template='Answer the following question based in the provided context and your internal knowledge.\\n    Give priority to context and if you are not sure then say you are not aware of topic:\\n    \\n    <context>\\n    {context}\\n    </context>\\n\\n    Question: {input}\\n    '))])\n",
       "            | Ollama(model='llama3')\n",
       "            | StrOutputParser(), config={'run_name': 'stuff_documents_chain'})\n",
       "  }), config={'run_name': 'retrieval_chain'})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains import create_retrieval_chain\n",
    "retrieval_chain = create_retrieval_chain(retriever, document_chain)\n",
    "retrieval_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = retrieval_chain.invoke({\"input\":\"Do you know about Claude 3?\"})\n",
    "type(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['input', 'context', 'answer'])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm not aware of a specific mention or details about Claude 3 in the provided context. However, I can see that there is a mention of Claude 3.5 Sonnet in the original text, which appears to be a model within the Claude family. It seems to offer advanced reasoning capabilities and has been introduced as part of the company's efforts to raise the industry bar for intelligence. If you're looking for more information about Claude 3, I'd suggest reaching out to Anthropic PBC or exploring their website and resources for further details.\n"
     ]
    }
   ],
   "source": [
    "print(response[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Meet Claude \\ Anthropic, Source:https://www.anthropic.com/claude\n",
      "Title: Releasing Claude Instant 1.2 \\ Anthropic, Source:https://www.anthropic.com/news/releasing-claude-instant-1-2\n"
     ]
    }
   ],
   "source": [
    "for doc in response[\"context\"]:\n",
    "    print(f\"Title: {doc.metadata['title']}, Source:{doc.metadata['source']}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
